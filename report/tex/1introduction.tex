\section{Introduction}
\label{intro}

Convolutional neural networks (ConvNets) have unparalleled capacity to learn high level semantic image features, but usually require large amounts to labeled data to train. Labeling data comes at a high cost and is not easily scalable. The field of self-supervised learning explores how supervisory signals can be learned from the data itself, often leveraging its underlying structure, thereby reducing the need for labels for predictive tasks like classification. In recent years, approaches like contrastive learning approach with SimCLR \cite{SimCLR} and unsupervised learning with RotNet to predict image rotations \cite{RotNet} have been gaining traction. In this project, we seek to replicate these approaches with a lighter network, and benchmark their performance against an established "supervised baseline".

    % Discriminative approaches learn representations using objective functions similar to those used for supervised learning, but train networks to perform pretext tasks where both the inputs and labels are derived from an unlabeled dataset. Many such approaches have relied on heuristics to design pretext tasks (Doersch et al., 2015\cite{convnet1}; Zhang et al., 2016\cite{convnet3}; Noroozi \& Favaro, 2016\cite{convnet2}; Gidaris et al., 2018\cite{RotNet}), which could limit the generality of the learned representations. Discriminative approaches based on contrastive learning in the latent space have recently shown great promise, achieving state-of-theart results (Hadsell et al., 2006\cite{convnet4}; Dosovitskiy et al., 2014\cite{convnet5}; Oord et al., 2018\cite{convnet6}; Bachman et al., 2019\cite{convnet7}).
